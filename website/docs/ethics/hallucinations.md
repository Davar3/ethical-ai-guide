# AI Hallucinations

Understanding and avoiding AI-generated misinformation.

## What are Hallucinations?

!!! danger "Definition"
    **AI Hallucinations** are confidently stated false information that AI generates as if it were true.

AI can:

- Invent fake citations and papers
- Create non-existent authors
- Generate plausible but false statistics
- Make up quotes

---

## Real Examples

### Fake Citations

❌ **AI says:** "Smith & Johnson (2023) found that..."

✅ **Reality:** This paper doesn't exist!

### Fake Statistics

❌ **AI says:** "According to a 2024 WHO report, 78% of..."

✅ **Reality:** No such report exists!

---

## How to Avoid Hallucinations

### 1. Always Verify Citations

- Search every citation on **Google Scholar**
- Check if the authors and journal are real
- Verify the publication year and DOI

### 2. Cross-Check Facts

- Use multiple sources
- Don't trust statistics without original source
- Verify quotes by searching the exact text

### 3. Use Grounded Tools

- **NotebookLM** - Only uses your uploaded sources
- **Perplexity** - Provides citations for claims
- Upload real PDFs rather than asking AI to find them

---

## The Golden Rule

!!! warning "Trust but Verify"
    Never include any AI-generated citation, statistic, or quote in your research without independently verifying it first.
